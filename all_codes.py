# -*- coding: utf-8 -*-
"""ALL CODES

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NuZZLcWectmIcVAiZRYQdsEyNZe5lgy5
"""

!pip install pycryptodome

import sqlite3
import pandas as pd
import time
import binascii
import tracemalloc

from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes
from Crypto.Util.Padding import pad


# -----------------------------
# 1) AES setup + dataset load
# -----------------------------
BLOCK_SIZE = 16
key = get_random_bytes(16)  # AES-128 key (16 bytes)

def aes_encrypt(text: str) -> str:
    """Encrypt a string with AES-CBC and return hex(iv + ciphertext)."""
    if pd.isna(text):
        return None
    data = str(text).encode('utf-8')
    iv = get_random_bytes(BLOCK_SIZE)
    cipher = AES.new(key, AES.MODE_CBC, iv)
    ct = cipher.encrypt(pad(data, BLOCK_SIZE))
    return binascii.hexlify(iv + ct).decode('utf-8')

df = pd.read_csv("customers.csv")
df = df.rename(columns={
    "CustomerID": "customer_id",
    "FirstName":  "first_name",
    "LastName":   "last_name",
    "Address":    "address",
    "Email":      "email",
    "Phone":      "phone_number"
})

print("Rows in dataset:", len(df))

SENSITIVE_COLS = ["first_name", "last_name", "address", "email", "phone_number"]


# -----------------------------
# Helpers: CPU + Memory + Storage
# -----------------------------
def measure_op(op_fn):
    """
    Measures:
    - latency (ms)
    - CPU % (process CPU time / wall time)
    - peak memory (MB) using tracemalloc
    """
    t0 = time.perf_counter()
    c0 = time.process_time()

    tracemalloc.start()
    op_fn()
    current, peak = tracemalloc.get_traced_memory()
    tracemalloc.stop()

    t1 = time.perf_counter()
    c1 = time.process_time()

    wall = t1 - t0
    latency_ms = wall * 1000.0
    cpu_pct = ((c1 - c0) / wall * 100.0) if wall > 0 else 0.0
    peak_mem_mb = peak / (1024 * 1024)

    return latency_ms, cpu_pct, peak_mem_mb


def df_bytes(d: pd.DataFrame, cols):
    total = 0
    for c in cols:
        s = d[c].fillna("").astype(str)
        total += s.map(lambda x: len(x.encode("utf-8"))).sum()
    return total


# -----------------------------
# 2) Single-run experiment
# -----------------------------
def run_experiment_once_aes():
    conn = sqlite3.connect(":memory:")
    cur = conn.cursor()

    cur.execute("""
        CREATE TABLE customers_plain (
            customer_id   INTEGER PRIMARY KEY,
            first_name    TEXT,
            last_name     TEXT,
            address       TEXT,
            email         TEXT,
            phone_number  TEXT
        );
    """)
    cur.execute("""
        CREATE TABLE customers_aes (
            customer_id   INTEGER PRIMARY KEY,
            first_name    TEXT,
            last_name     TEXT,
            address       TEXT,
            email         TEXT,
            phone_number  TEXT
        );
    """)
    conn.commit()

    # INSERT plaintext
    plain_insert_ms, plain_insert_cpu, plain_insert_mem = measure_op(
        lambda: df.to_sql("customers_plain", conn, if_exists="append", index=False)
    )

    # Build AES encrypted dataframe
    enc_df = df.copy()
    for col in SENSITIVE_COLS:
        enc_df[col] = enc_df[col].apply(aes_encrypt)

    # Storage overhead (sensitive columns only)
    plain_bytes = df_bytes(df, SENSITIVE_COLS)
    enc_bytes = df_bytes(enc_df, SENSITIVE_COLS)
    storage_overhead_pct = ((enc_bytes - plain_bytes) / plain_bytes * 100.0) if plain_bytes else 0.0

    # INSERT AES
    aes_insert_ms, aes_insert_cpu, aes_insert_mem = measure_op(
        lambda: enc_df.to_sql("customers_aes", conn, if_exists="append", index=False)
    )

    def select_all(table):
        cur.execute(f"SELECT * FROM {table} WHERE 1=1")
        return cur.fetchall()

    def update_all(table):
        cur.execute(f"UPDATE {table} SET address = address || '_X' WHERE 1=1;")
        conn.commit()

    def delete_half(table):
        """Delete approximately half of the records (those with even customer_id)"""
        cur.execute(f"DELETE FROM {table} WHERE customer_id % 2 = 0;")
        conn.commit()

    # SELECT all rows
    plain_select_ms, plain_select_cpu, plain_select_mem = measure_op(lambda: select_all("customers_plain"))
    aes_select_ms,   aes_select_cpu,   aes_select_mem   = measure_op(lambda: select_all("customers_aes"))

    cur.execute("SELECT COUNT(*) FROM customers_plain")
    total_rows = cur.fetchone()[0]

    # UPDATE all rows
    plain_update_ms, plain_update_cpu, plain_update_mem = measure_op(lambda: update_all("customers_plain"))
    aes_update_ms,   aes_update_cpu,   aes_update_mem   = measure_op(lambda: update_all("customers_aes"))

    # DELETE half of the rows
    plain_delete_ms, plain_delete_cpu, plain_delete_mem = measure_op(lambda: delete_half("customers_plain"))
    aes_delete_ms,   aes_delete_cpu,   aes_delete_mem   = measure_op(lambda: delete_half("customers_aes"))

    # Count remaining rows after delete
    cur.execute("SELECT COUNT(*) FROM customers_plain")
    rows_after_delete = cur.fetchone()[0]
    rows_deleted = total_rows - rows_after_delete


    conn.close()

    return {
        "total_rows": total_rows,
        "rows_after_delete": rows_after_delete,
        "rows_deleted": rows_deleted,


        "plain_insert_ms": plain_insert_ms,
        "plain_insert_cpu": plain_insert_cpu,
        "plain_insert_mem": plain_insert_mem,

        "aes_insert_ms": aes_insert_ms,
        "aes_insert_cpu": aes_insert_cpu,
        "aes_insert_mem": aes_insert_mem,

        "plain_select_ms": plain_select_ms,
        "plain_select_cpu": plain_select_cpu,
        "plain_select_mem": plain_select_mem,

        "aes_select_ms": aes_select_ms,
        "aes_select_cpu": aes_select_cpu,
        "aes_select_mem": aes_select_mem,

        "plain_update_ms": plain_update_ms,
        "plain_update_cpu": plain_update_cpu,
        "plain_update_mem": plain_update_mem,

        "aes_update_ms": aes_update_ms,
        "aes_update_cpu": aes_update_cpu,
        "aes_update_mem": aes_update_mem,

        "plain_delete_ms": plain_delete_ms,
        "plain_delete_cpu": plain_delete_cpu,
        "plain_delete_mem": plain_delete_mem,

        "aes_delete_ms": aes_delete_ms,
        "aes_delete_cpu": aes_delete_cpu,
        "aes_delete_mem": aes_delete_mem,

        "storage_plain_mb": plain_bytes / (1024 * 1024),
        "storage_enc_mb": enc_bytes / (1024 * 1024),
        "storage_overhead_pct": storage_overhead_pct,
    }


# -----------------------------
# 3) Run multiple times + average
# -----------------------------
N_RUNS = 5
runs = [run_experiment_once_aes() for _ in range(N_RUNS)]
runs_df = pd.DataFrame(runs)
avg = runs_df.mean(numeric_only=True).to_dict()

total_rows = int(runs[0]["total_rows"])
rows_deleted = int(runs[0]["rows_deleted"])



def overhead(enc, plain):
    return ((enc - plain) / plain * 100.0) if plain else 0.0

def throughput(rows, latency_ms):
    return rows / (latency_ms / 1000.0) if latency_ms else 0.0

results_aes = pd.DataFrame([
    ["INSERT", "Plaintext", total_rows, avg["plain_insert_ms"], avg["plain_insert_cpu"], avg["plain_insert_mem"],
     throughput(total_rows, avg["plain_insert_ms"]), 0.0],

    ["INSERT", "AES",       total_rows, avg["aes_insert_ms"],   avg["aes_insert_cpu"],   avg["aes_insert_mem"],
     throughput(total_rows, avg["aes_insert_ms"]),
     overhead(avg["aes_insert_ms"], avg["plain_insert_ms"])],

    ["SELECT", "Plaintext", total_rows, avg["plain_select_ms"], avg["plain_select_cpu"], avg["plain_select_mem"],
     throughput(total_rows, avg["plain_select_ms"]), 0.0],

    ["SELECT", "AES",       total_rows, avg["aes_select_ms"],   avg["aes_select_cpu"],   avg["aes_select_mem"],
     throughput(total_rows, avg["aes_select_ms"]),
     overhead(avg["aes_select_ms"], avg["plain_select_ms"])],

    ["UPDATE", "Plaintext", total_rows, avg["plain_update_ms"], avg["plain_update_cpu"], avg["plain_update_mem"],
     throughput(total_rows, avg["plain_update_ms"]), 0.0],

    ["UPDATE", "AES",       total_rows, avg["aes_update_ms"],   avg["aes_update_cpu"],   avg["aes_update_mem"],
     throughput(total_rows, avg["aes_update_ms"]),
     overhead(avg["aes_update_ms"], avg["plain_update_ms"])],

    ["DELETE", "Plaintext", rows_deleted, avg["plain_delete_ms"], avg["plain_delete_cpu"], avg["plain_delete_mem"],
     throughput(rows_deleted, avg["plain_delete_ms"]), 0.0],

    ["DELETE", "AES",       rows_deleted, avg["aes_delete_ms"],   avg["aes_delete_cpu"],   avg["aes_delete_mem"],
     throughput(rows_deleted, avg["aes_delete_ms"]),
     overhead(avg["aes_delete_ms"], avg["plain_delete_ms"])],

], columns=[
    "Operation", "Mode", "Rows",
    "Latency_ms", "CPU_pct", "PeakMem_MB",
    "Throughput_rows_per_s", "Overhead_pct"
])

pd.set_option("display.float_format", lambda x: f"{x:,.3f}")

print(f"\n=== AES performance (average of {N_RUNS} runs, {total_rows} rows) ===")
print(results_aes.to_string(index=False))

print("\n=== Storage Overhead (sensitive columns only) ===")
print(f"Plaintext (MB): {avg['storage_plain_mb']:.3f}")
print(f"Encrypted  (MB): {avg['storage_enc_mb']:.3f}")
print(f"Overhead    (%): {avg['storage_overhead_pct']:.2f}")

results_aes.to_csv("aes_results.csv", index=False)

# -*- coding: utf-8 -*-
"""RSA CODE WITH DELETE OPERATION

Updated version including DELETE operation measurement
"""
!pip install pycryptodome
import sqlite3
import pandas as pd
import time
import binascii
import tracemalloc

from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP
from Crypto.Cipher import AES
from Crypto.Random import get_random_bytes
from Crypto.Util.Padding import pad


# -----------------------------
# 1) Load dataset
# -----------------------------
df = pd.read_csv("customers.csv")

df = df.rename(columns={
    "CustomerID": "customer_id",
    "FirstName":  "first_name",
    "LastName":   "last_name",
    "Address":    "address",
    "Email":      "email",
    "Phone":      "phone_number"
})

print("Rows in dataset:", len(df))
print(df.head()[["customer_id", "first_name", "last_name", "address"]])
print(df.head()[["email", "phone_number"]])

SENSITIVE_COLS = ["first_name", "last_name", "address", "email", "phone_number"]


# -----------------------------
# 2) RSA setup (2048-bit, OAEP)
# -----------------------------
rsa_key = RSA.generate(2048)
rsa_pub = rsa_key.publickey()
rsa_cipher = PKCS1_OAEP.new(rsa_pub)


def rsa_encrypt(text: str) -> str:
    """
    Hybrid RSA encryption for large messages:
    - Generate random AES key
    - Encrypt data with AES-CBC
    - Encrypt AES key with RSA-OAEP
    - Return hex( len(enc_key)||enc_key||iv||ciphertext )
    """
    if pd.isna(text):
        return None

    data = str(text).encode("utf-8")

    aes_key = get_random_bytes(16)
    iv = get_random_bytes(16)

    cipher = AES.new(aes_key, AES.MODE_CBC, iv)
    ct = cipher.encrypt(pad(data, 16))

    enc_key = rsa_cipher.encrypt(aes_key)

    blob = len(enc_key).to_bytes(2, "big") + enc_key + iv + ct
    return binascii.hexlify(blob).decode("utf-8")


# -----------------------------
# Helpers: CPU + Memory + Storage
# -----------------------------
def measure_op(op_fn):
    """
    Measures:
    - latency (ms)
    - CPU % (process CPU time / wall time)
    - peak memory (MB) using tracemalloc
    """
    t0 = time.perf_counter()
    c0 = time.process_time()

    tracemalloc.start()
    op_fn()
    current, peak = tracemalloc.get_traced_memory()
    tracemalloc.stop()

    t1 = time.perf_counter()
    c1 = time.process_time()

    wall = t1 - t0
    latency_ms = wall * 1000.0
    cpu_pct = ((c1 - c0) / wall * 100.0) if wall > 0 else 0.0
    peak_mem_mb = peak / (1024 * 1024)

    return latency_ms, cpu_pct, peak_mem_mb


def df_bytes(d: pd.DataFrame, cols):
    total = 0
    for c in cols:
        s = d[c].fillna("").astype(str)
        total += s.map(lambda x: len(x.encode("utf-8"))).sum()
    return total


# -----------------------------
# 3) Single-run experiment
# -----------------------------
def run_experiment_once_rsa():
    conn = sqlite3.connect(":memory:")
    cur = conn.cursor()

    cur.execute("""
        CREATE TABLE customers_plain (
            customer_id   INTEGER PRIMARY KEY,
            first_name    TEXT,
            last_name     TEXT,
            address       TEXT,
            email         TEXT,
            phone_number  TEXT
        );
    """)
    cur.execute("""
        CREATE TABLE customers_rsa (
            customer_id   INTEGER PRIMARY KEY,
            first_name    TEXT,
            last_name     TEXT,
            address       TEXT,
            email         TEXT,
            phone_number  TEXT
        );
    """)
    conn.commit()

    # INSERT plaintext (timed)
    plain_insert_ms, plain_insert_cpu, plain_insert_mem = measure_op(
        lambda: df.to_sql("customers_plain", conn, if_exists="append", index=False)
    )

    # Build encrypted dataframe
    enc_df = df.copy()
    for col in SENSITIVE_COLS:
        enc_df[col] = enc_df[col].apply(rsa_encrypt)

    # Storage overhead (bytes of sensitive fields, plaintext vs encrypted)
    plain_bytes = df_bytes(df, SENSITIVE_COLS)
    enc_bytes = df_bytes(enc_df, SENSITIVE_COLS)
    storage_overhead_pct = ((enc_bytes - plain_bytes) / plain_bytes * 100.0) if plain_bytes else 0.0

    # INSERT RSA (timed)
    rsa_insert_ms, rsa_insert_cpu, rsa_insert_mem = measure_op(
        lambda: enc_df.to_sql("customers_rsa", conn, if_exists="append", index=False)
    )

    def select_all(table):
        cur.execute(f"SELECT * FROM {table} WHERE 1=1")
        return cur.fetchall()

    def update_all(table):
        cur.execute(f"UPDATE {table} SET address = address || '_X' WHERE 1=1;")
        conn.commit()

    def delete_half(table):
        """Delete approximately half of the records (those with even customer_id)"""
        cur.execute(f"DELETE FROM {table} WHERE customer_id % 2 = 0;")
        conn.commit()

    # SELECT all rows (timed)
    plain_select_ms, plain_select_cpu, plain_select_mem = measure_op(lambda: select_all("customers_plain"))
    rsa_select_ms,   rsa_select_cpu,   rsa_select_mem   = measure_op(lambda: select_all("customers_rsa"))

    # Row counts (after select)
    cur.execute("SELECT COUNT(*) FROM customers_plain")
    total_rows = cur.fetchone()[0]

    # UPDATE all rows (timed)
    plain_update_ms, plain_update_cpu, plain_update_mem = measure_op(lambda: update_all("customers_plain"))
    rsa_update_ms,   rsa_update_cpu,   rsa_update_mem   = measure_op(lambda: update_all("customers_rsa"))

    # DELETE half of the rows (timed)
    plain_delete_ms, plain_delete_cpu, plain_delete_mem = measure_op(lambda: delete_half("customers_plain"))
    rsa_delete_ms,   rsa_delete_cpu,   rsa_delete_mem   = measure_op(lambda: delete_half("customers_rsa"))

    # Count remaining rows after delete
    cur.execute("SELECT COUNT(*) FROM customers_plain")
    rows_after_delete = cur.fetchone()[0]
    rows_deleted = total_rows - rows_after_delete

    conn.close()

    return {
        "total_rows": total_rows,
        "rows_after_delete": rows_after_delete,
        "rows_deleted": rows_deleted,

        "plain_insert_ms": plain_insert_ms,
        "plain_insert_cpu": plain_insert_cpu,
        "plain_insert_mem": plain_insert_mem,

        "rsa_insert_ms": rsa_insert_ms,
        "rsa_insert_cpu": rsa_insert_cpu,
        "rsa_insert_mem": rsa_insert_mem,

        "plain_select_ms": plain_select_ms,
        "plain_select_cpu": plain_select_cpu,
        "plain_select_mem": plain_select_mem,

        "rsa_select_ms": rsa_select_ms,
        "rsa_select_cpu": rsa_select_cpu,
        "rsa_select_mem": rsa_select_mem,

        "plain_update_ms": plain_update_ms,
        "plain_update_cpu": plain_update_cpu,
        "plain_update_mem": plain_update_mem,

        "rsa_update_ms": rsa_update_ms,
        "rsa_update_cpu": rsa_update_cpu,
        "rsa_update_mem": rsa_update_mem,

        "plain_delete_ms": plain_delete_ms,
        "plain_delete_cpu": plain_delete_cpu,
        "plain_delete_mem": plain_delete_mem,

        "rsa_delete_ms": rsa_delete_ms,
        "rsa_delete_cpu": rsa_delete_cpu,
        "rsa_delete_mem": rsa_delete_mem,

        "storage_plain_mb": plain_bytes / (1024 * 1024),
        "storage_enc_mb": enc_bytes / (1024 * 1024),
        "storage_overhead_pct": storage_overhead_pct,
    }


# -----------------------------
# 4) Run multiple times + average
# -----------------------------
N_RUNS = 5
runs = [run_experiment_once_rsa() for _ in range(N_RUNS)]
runs_df = pd.DataFrame(runs)
avg = runs_df.mean(numeric_only=True).to_dict()

total_rows = int(runs[0]["total_rows"])
rows_deleted = int(runs[0]["rows_deleted"])

def overhead(enc, plain):
    return ((enc - plain) / plain * 100.0) if plain else 0.0

def throughput(rows, latency_ms):
    return rows / (latency_ms / 1000.0) if latency_ms else 0.0


results_rsa = pd.DataFrame([
    ["INSERT", "Plaintext", total_rows, avg["plain_insert_ms"], avg["plain_insert_cpu"], avg["plain_insert_mem"],
     throughput(total_rows, avg["plain_insert_ms"]), 0.0],

    ["INSERT", "RSA",       total_rows, avg["rsa_insert_ms"],   avg["rsa_insert_cpu"],   avg["rsa_insert_mem"],
     throughput(total_rows, avg["rsa_insert_ms"]),
     overhead(avg["rsa_insert_ms"], avg["plain_insert_ms"])],

    ["SELECT", "Plaintext", total_rows, avg["plain_select_ms"], avg["plain_select_cpu"], avg["plain_select_mem"],
     throughput(total_rows, avg["plain_select_ms"]), 0.0],

    ["SELECT", "RSA",       total_rows, avg["rsa_select_ms"],   avg["rsa_select_cpu"],   avg["rsa_select_mem"],
     throughput(total_rows, avg["rsa_select_ms"]),
     overhead(avg["rsa_select_ms"], avg["plain_select_ms"])],

    ["UPDATE", "Plaintext", total_rows, avg["plain_update_ms"], avg["plain_update_cpu"], avg["plain_update_mem"],
     throughput(total_rows, avg["plain_update_ms"]), 0.0],

    ["UPDATE", "RSA",       total_rows, avg["rsa_update_ms"],   avg["rsa_update_cpu"],   avg["rsa_update_mem"],
     throughput(total_rows, avg["rsa_update_ms"]),
     overhead(avg["rsa_update_ms"], avg["plain_update_ms"])],

    ["DELETE", "Plaintext", rows_deleted, avg["plain_delete_ms"], avg["plain_delete_cpu"], avg["plain_delete_mem"],
     throughput(rows_deleted, avg["plain_delete_ms"]), 0.0],

    ["DELETE", "RSA",       rows_deleted, avg["rsa_delete_ms"],   avg["rsa_delete_cpu"],   avg["rsa_delete_mem"],
     throughput(rows_deleted, avg["rsa_delete_ms"]),
     overhead(avg["rsa_delete_ms"], avg["plain_delete_ms"])],
], columns=[
    "Operation", "Mode", "Rows",
    "Latency_ms", "CPU_pct", "PeakMem_MB",
    "Throughput_rows_per_s", "Overhead_pct"
])

pd.set_option("display.float_format", lambda x: f"{x:,.3f}")

print(f"\n=== RSA performance (average of {N_RUNS} runs, {total_rows} rows) ===")
print(results_rsa.to_string(index=False))

print("\n=== Storage Overhead (sensitive columns only) ===")
print(f"Plaintext (MB): {avg['storage_plain_mb']:.3f}")
print(f"Encrypted  (MB): {avg['storage_enc_mb']:.3f}")
print(f"Overhead    (%): {avg['storage_overhead_pct']:.2f}")

results_rsa.to_csv("rsa_results.csv", index=False)

##ECC CODE

!pip install pycryptodome psutil

import sqlite3
import pandas as pd
import time
import binascii
import tracemalloc

from Crypto.PublicKey import ECC
from Crypto.Cipher import AES
from Crypto.Hash import SHA256
from Crypto.Random import get_random_bytes
from IPython.display import display

# -----------------------------
# 1) ECC setup + dataset load
# -----------------------------
ecc_key = ECC.generate(curve="P-256")
ecc_pub = ecc_key.public_key()

def ecc_encrypt(text: str) -> str:
    """
    ECIES-style encryption:
    - Generate ephemeral ECC key
    - Derive shared secret with receiver's public key (ECDH)
    - Hash shared secret -> AES key
    - Encrypt plaintext with AES-GCM
    - Return hex( len(eph_pub)||eph_pub||iv||tag||ciphertext )
    """
    if pd.isna(text):
        return None

    data = str(text).encode("utf-8")

    eph_key = ECC.generate(curve="P-256")

    shared_point = eph_key.d * ecc_pub.pointQ
    shared_x = int(shared_point.x).to_bytes(32, "big")

    aes_key = SHA256.new(shared_x).digest()

    iv = get_random_bytes(12)
    cipher = AES.new(aes_key, AES.MODE_GCM, nonce=iv)
    ct, tag = cipher.encrypt_and_digest(data)

    eph_pub_bytes = eph_key.public_key().export_key(format="DER")
    blob = (
        len(eph_pub_bytes).to_bytes(2, "big")
        + eph_pub_bytes
        + iv
        + tag
        + ct
    )
    return binascii.hexlify(blob).decode("utf-8")


df = pd.read_csv("customers.csv")
df = df.rename(columns={
    "CustomerID": "customer_id",
    "FirstName":  "first_name",
    "LastName":   "last_name",
    "Address":    "address",
    "Email":      "email",
    "Phone":      "phone_number"
})

print("Rows in dataset:", len(df))

SENSITIVE_COLS = ["first_name", "last_name", "address", "email", "phone_number"]


# -----------------------------
# Helpers: CPU + Memory + Storage
# -----------------------------
def measure_op(op_fn):
    """
    Measures:
    - latency (ms)
    - CPU % (process CPU time / wall time)
    - peak memory (MB) using tracemalloc
    """
    t0 = time.perf_counter()
    c0 = time.process_time()

    tracemalloc.start()
    op_fn()
    current, peak = tracemalloc.get_traced_memory()
    tracemalloc.stop()

    t1 = time.perf_counter()
    c1 = time.process_time()

    wall = t1 - t0
    latency_ms = wall * 1000.0
    cpu_pct = ((c1 - c0) / wall * 100.0) if wall > 0 else 0.0
    peak_mem_mb = peak / (1024 * 1024)

    return latency_ms, cpu_pct, peak_mem_mb


def df_bytes(d: pd.DataFrame, cols):
    total = 0
    for c in cols:
        s = d[c].fillna("").astype(str)
        total += s.map(lambda x: len(x.encode("utf-8"))).sum()
    return total


# -----------------------------
# 2) Single-run experiment
# -----------------------------
def run_experiment_once_ecc():
    conn = sqlite3.connect(":memory:")
    cur = conn.cursor()

    cur.execute("""
        CREATE TABLE customers_plain (
            customer_id   INTEGER PRIMARY KEY,
            first_name    TEXT,
            last_name     TEXT,
            address       TEXT,
            email         TEXT,
            phone_number  TEXT
        );
    """)
    cur.execute("""
        CREATE TABLE customers_ecc (
            customer_id   INTEGER PRIMARY KEY,
            first_name    TEXT,
            last_name     TEXT,
            address       TEXT,
            email         TEXT,
            phone_number  TEXT
        );
    """)
    conn.commit()

    # INSERT plaintext
    plain_insert_ms, plain_insert_cpu, plain_insert_mem = measure_op(
        lambda: df.to_sql("customers_plain", conn, if_exists="append", index=False)
    )

    # Build ECC encrypted dataframe (encryption step not included in INSERT timer, same style as your original)
    enc_df = df.copy()
    for col in SENSITIVE_COLS:
        enc_df[col] = enc_df[col].apply(ecc_encrypt)

    # Storage overhead (sensitive columns only)
    plain_bytes = df_bytes(df, SENSITIVE_COLS)
    enc_bytes = df_bytes(enc_df, SENSITIVE_COLS)
    storage_overhead_pct = ((enc_bytes - plain_bytes) / plain_bytes * 100.0) if plain_bytes else 0.0

    # INSERT ECC
    ecc_insert_ms, ecc_insert_cpu, ecc_insert_mem = measure_op(
        lambda: enc_df.to_sql("customers_ecc", conn, if_exists="append", index=False)
    )

    def select_all(table):
        cur.execute(f"SELECT * FROM {table} WHERE 1=1")
        return cur.fetchall()

    def update_all(table):
        cur.execute(f"UPDATE {table} SET address = address || '_X' WHERE 1=1;")
        conn.commit()

    def delete_half(table):
        cur.execute(f"DELETE FROM {table} WHERE customer_id % 2 = 0;")
        conn.commit()

    # SELECT all rows
    plain_select_ms, plain_select_cpu, plain_select_mem = measure_op(lambda: select_all("customers_plain"))
    ecc_select_ms,   ecc_select_cpu,   ecc_select_mem   = measure_op(lambda: select_all("customers_ecc"))

    cur.execute("SELECT COUNT(*) FROM customers_plain")
    total_rows = cur.fetchone()[0]

    # UPDATE all rows
    plain_update_ms, plain_update_cpu, plain_update_mem = measure_op(lambda: update_all("customers_plain"))
    ecc_update_ms,   ecc_update_cpu,   ecc_update_mem   = measure_op(lambda: update_all("customers_ecc"))

    # DELETE half of the records
    plain_delete_ms, plain_delete_cpu, plain_delete_mem = measure_op(lambda: delete_half("customers_plain"))
    ecc_delete_ms,   ecc_delete_cpu,   ecc_delete_mem   = measure_op(lambda: delete_half("customers_ecc"))

    # Count remaining rows after delete
    cur.execute("SELECT COUNT(*) FROM customers_plain")
    rows_after_delete = cur.fetchone()[0]
    rows_deleted = total_rows - rows_after_delete

    conn.close()

    return {
        "total_rows": total_rows,
        "rows_after_delete": rows_after_delete,
        "rows_deleted": rows_deleted,

        "plain_insert_ms": plain_insert_ms,
        "plain_insert_cpu": plain_insert_cpu,
        "plain_insert_mem": plain_insert_mem,

        "ecc_insert_ms": ecc_insert_ms,
        "ecc_insert_cpu": ecc_insert_cpu,
        "ecc_insert_mem": ecc_insert_mem,

        "plain_select_ms": plain_select_ms,
        "plain_select_cpu": plain_select_cpu,
        "plain_select_mem": plain_select_mem,

        "ecc_select_ms": ecc_select_ms,
        "ecc_select_cpu": ecc_select_cpu,
        "ecc_select_mem": ecc_select_mem,

        "plain_update_ms": plain_update_ms,
        "plain_update_cpu": plain_update_cpu,
        "plain_update_mem": plain_update_mem,

        "ecc_update_ms": ecc_update_ms,
        "ecc_update_cpu": ecc_update_cpu,
        "ecc_update_mem": ecc_update_mem,

        "plain_delete_ms": plain_delete_ms,
        "plain_delete_cpu": plain_delete_cpu,
        "plain_delete_mem": plain_delete_mem,

        "ecc_delete_ms": ecc_delete_ms,
        "ecc_delete_cpu": ecc_delete_cpu,
        "ecc_delete_mem": ecc_delete_mem,

        "storage_plain_mb": plain_bytes / (1024 * 1024),
        "storage_enc_mb": enc_bytes / (1024 * 1024),
        "storage_overhead_pct": storage_overhead_pct,
    }


# -----------------------------
# 3) Run multiple times + average
# -----------------------------
N_RUNS = 5
runs = [run_experiment_once_ecc() for _ in range(N_RUNS)]
runs_df = pd.DataFrame(runs)
avg = runs_df.mean(numeric_only=True).to_dict()

total_rows = int(runs[0]["total_rows"])
rows_deleted = int(runs[0]["rows_deleted"])

def overhead(enc, plain):
    return ((enc - plain) / plain * 100.0) if plain else 0.0

def throughput(rows, latency_ms):
    return rows / (latency_ms / 1000.0) if latency_ms else 0.0

results_ecc = pd.DataFrame([
    ["INSERT", "Plaintext", total_rows, avg["plain_insert_ms"], avg["plain_insert_cpu"], avg["plain_insert_mem"],
     throughput(total_rows, avg["plain_insert_ms"]), 0.0],

    ["INSERT", "ECC",       total_rows, avg["ecc_insert_ms"],   avg["ecc_insert_cpu"],   avg["ecc_insert_mem"],
     throughput(total_rows, avg["ecc_insert_ms"]),
     overhead(avg["ecc_insert_ms"], avg["plain_insert_ms"])],

    ["SELECT", "Plaintext", total_rows, avg["plain_select_ms"], avg["plain_select_cpu"], avg["plain_select_mem"],
     throughput(total_rows, avg["plain_select_ms"]), 0.0],

    ["SELECT", "ECC",       total_rows, avg["ecc_select_ms"],   avg["ecc_select_cpu"],   avg["ecc_select_mem"],
     throughput(total_rows, avg["ecc_select_ms"]),
     overhead(avg["ecc_select_ms"], avg["plain_select_ms"])],

    ["UPDATE", "Plaintext", total_rows, avg["plain_update_ms"], avg["plain_update_cpu"], avg["plain_update_mem"],
     throughput(total_rows, avg["plain_update_ms"]), 0.0],

    ["UPDATE", "ECC",       total_rows, avg["ecc_update_ms"],   avg["ecc_update_cpu"],   avg["ecc_update_mem"],
     throughput(total_rows, avg["ecc_update_ms"]),
     overhead(avg["ecc_update_ms"], avg["plain_update_ms"])],

     ["DELETE", "Plaintext", rows_deleted, avg["plain_delete_ms"], avg["plain_delete_cpu"], avg["plain_delete_mem"],
     throughput(rows_deleted, avg["plain_delete_ms"]), 0.0],

    ["DELETE", "ECC",       rows_deleted, avg["ecc_delete_ms"],   avg["ecc_delete_cpu"],   avg["ecc_delete_mem"],
     throughput(rows_deleted, avg["ecc_delete_ms"]),
     overhead(avg["ecc_delete_ms"], avg["plain_delete_ms"])],
    ], columns=[
    "Operation", "Mode", "Rows",
    "Latency_ms", "CPU_pct", "PeakMem_MB",
    "Throughput_rows_per_s", "Overhead_pct"
])

pd.set_option("display.float_format", lambda x: f"{x:,.3f}")

print(f"\n=== ECC performance (average of {N_RUNS} runs, {total_rows} rows) ===")
print(results_ecc.to_string(index=False))

print("\n=== Storage Overhead (sensitive columns only) ===")
print(f"Plaintext (MB): {avg['storage_plain_mb']:.3f}")
print(f"Encrypted  (MB): {avg['storage_enc_mb']:.3f}")
print(f"Overhead    (%): {avg['storage_overhead_pct']:.2f}")

results_ecc.to_csv("ecc_results.csv", index=False)